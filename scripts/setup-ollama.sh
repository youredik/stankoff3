#!/bin/bash
# –°–∫—Ä–∏–ø—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Ollama —Å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
#
# –ó–∞–ø—É—Å–∫:
#   ./scripts/setup-ollama.sh
#
# –ú–æ–¥–µ–ª–∏:
#   - nomic-embed-text: –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω—ã–µ embeddings (768 dims, 274MB)
#   - qwen2.5:14b: LLM —Å —Ö–æ—Ä–æ—à–µ–π –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä—É—Å—Å–∫–æ–≥–æ (9GB)
#   - llama3.1:8b: –±—ã—Å—Ç—Ä–∞—è LLM –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ (4.7GB)

set -e

echo "üöÄ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Ollama –¥–ª—è Stankoff Portal..."

# –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–ø—É—â–µ–Ω –ª–∏ Docker
if ! docker info > /dev/null 2>&1; then
    echo "‚ùå Docker –Ω–µ –∑–∞–ø—É—â–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–ø—É—Å—Ç–∏—Ç–µ Docker."
    exit 1
fi

# –ó–∞–ø—É—Å–∫–∞–µ–º Ollama –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
echo "üì¶ –ó–∞–ø—É—Å–∫ Ollama –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞..."
docker compose -f docker-compose.ollama.yml up -d

# –ñ–¥—ë–º –ø–æ–∫–∞ Ollama –±—É–¥–µ—Ç –≥–æ—Ç–æ–≤
echo "‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ Ollama..."
max_attempts=30
attempt=0
while [ $attempt -lt $max_attempts ]; do
    if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
        echo "‚úÖ Ollama –≥–æ—Ç–æ–≤!"
        break
    fi
    attempt=$((attempt + 1))
    sleep 2
done

if [ $attempt -eq $max_attempts ]; then
    echo "‚ùå Ollama –Ω–µ –∑–∞–ø—É—Å—Ç–∏–ª—Å—è. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏: docker logs stankoff-ollama"
    exit 1
fi

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏
echo ""
echo "üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ nomic-embed-text (embeddings, 274MB)..."
docker compose -f docker-compose.ollama.yml exec -T ollama ollama pull nomic-embed-text

echo ""
echo "üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ qwen2.5:14b (LLM, 9GB)..."
echo "   –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç..."
docker compose -f docker-compose.ollama.yml exec -T ollama ollama pull qwen2.5:14b

# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –∑–∞–≥—Ä—É–∂–∞–µ–º –±—ã—Å—Ç—Ä—É—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É
read -p "–•–æ—Ç–∏—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –º–æ–¥–µ–ª—å llama3.1:8b (4.7GB)? [y/N] " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo "üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ llama3.1:8b..."
    docker compose -f docker-compose.ollama.yml exec -T ollama ollama pull llama3.1:8b
fi

echo ""
echo "‚úÖ Ollama –Ω–∞—Å—Ç—Ä–æ–µ–Ω!"
echo ""
echo "üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:"
docker compose -f docker-compose.ollama.yml exec -T ollama ollama list
echo ""
echo "üîß –î–æ–±–∞–≤—å—Ç–µ –≤ .env:"
echo "   OLLAMA_BASE_URL=http://localhost:11434"
echo "   OLLAMA_MODEL=qwen2.5:14b"
echo "   OLLAMA_EMBEDDING_MODEL=nomic-embed-text"
echo "   AI_LLM_PRIORITY=yandex,ollama,openai"
echo "   AI_EMBEDDING_PRIORITY=ollama,openai"
echo ""
echo "üöÄ –¢–µ–ø–µ—Ä—å –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å backend: npm run dev:backend"
